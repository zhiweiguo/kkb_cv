{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问题回答\n",
    "### 1. 为什么模型的最开始要加入padding=100进行填充？\n",
    "#### 通过padding=100，可以保证能够接受任意尺寸的输入图像\n",
    "### 2. 在上采样阶段，为什么需要裁剪？\n",
    "#### 由于上采样后的尺寸与下采样阶段的特征图尺寸不一致，通过裁减到一样的尺寸，拼接起来再做后续的操作，直到最后得到与输入相同的尺寸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重构了fcn的参考代码，并对各个模型结构进行了对比验证，可以跑通，但是由于预训练模型的tensor名称与自己模型中的定义不一致，需要更改名称后再读入模型，因此暂时没有与原版的fcn8s进行对比验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fcn8s import FCN8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上采样权重参数生成\n",
    "# https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/surgery.py\n",
    "def get_upsampling_weight(in_channels, out_channels, kernel_size):\n",
    "    \"\"\"Make a 2D bilinear kernel suitable for upsampling\"\"\"\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size),\n",
    "                      dtype=np.float64)\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return torch.from_numpy(weight).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 支持所有的vgg结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = [\n",
    "    'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n",
    "    'vgg19_bn', 'vgg19',\n",
    "]\n",
    "\n",
    "# 对官方的配置方式进行了修改，适配当前的fcn\n",
    "vgg_cfgs = {\n",
    "    'vgg_11': [[64, 'M'], [128, 'M'], [256, 256, 'M'], [512, 512, 'M'], [512, 512, 'M']],\n",
    "    'vgg_13': [[64, 64, 'M'], [128, 128, 'M'], [256, 256, 'M'], [512, 512, 'M'], [512, 512, 'M']],\n",
    "    'vgg_16': [[64, 64, 'M'], [128, 128, 'M'], [256, 256, 256, 'M'], [512, 512, 512, 'M'], [512, 512, 512, 'M']],\n",
    "    'vgg_19': [[64, 64, 'M'], [128, 128, 'M'], [256, 256, 256, 256, 'M'], [512, 512, 512, 512, 'M'], [512, 512, 512, 512, 'M']],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN网络结构定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):   \n",
    "    def __init__(self, vgg_cfgs, mode=8, n_class=21):\n",
    "        super(FCN, self).__init__()\n",
    "\n",
    "        self.mode = mode\n",
    "\n",
    "        self.in_channels = 3  # 输入通道\n",
    "        self.padding = 100    # 首次卷积padding\n",
    "\n",
    "        self.vgg_stage1 = self.make_stage_layers(vgg_cfgs[0])    # 1/2\n",
    "        self.vgg_stage2 = self.make_stage_layers(vgg_cfgs[1])    # 1/4\n",
    "        self.vgg_stage3 = self.make_stage_layers(vgg_cfgs[2])    # 1/8\n",
    "        self.vgg_stage4 = self.make_stage_layers(vgg_cfgs[3])    # 1/16\n",
    "        self.vgg_stage5 = self.make_stage_layers(vgg_cfgs[4])    # 1/32\n",
    "\n",
    "        self.fc6 = nn.Sequential(\n",
    "            nn.Conv2d(512, 4096, 7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(),\n",
    "        )\n",
    "        self.fc7 = nn.Sequential(\n",
    "            nn.Conv2d(4096, 4096, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(),\n",
    "        )\n",
    "\n",
    "        self.score_fr = nn.Conv2d(4096, n_class, 1)\n",
    "        #self.upscore = self.make_upscore_layers()   # upsample\n",
    "        self.score_pool3 = nn.Conv2d(256, n_class, 1)\n",
    "        self.score_pool4 = nn.Conv2d(512, n_class, 1)\n",
    "\n",
    "        self.upscore = nn.ConvTranspose2d(\n",
    "            n_class, n_class, 64, stride=32, bias=False)\n",
    "        self.upscore2 = nn.ConvTranspose2d(\n",
    "            n_class, n_class, 4, stride=2, bias=False)\n",
    "        self.upscore8 = nn.ConvTranspose2d(\n",
    "            n_class, n_class, 16, stride=8, bias=False)\n",
    "        self.upscore16 = nn.ConvTranspose2d(\n",
    "            n_class, n_class, 32, stride=16, bias=False)\n",
    "\n",
    "        self.upscore_pool4 = nn.ConvTranspose2d(\n",
    "            n_class, n_class, 4, stride=2, bias=False)\n",
    "        \n",
    "        #self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                #m.weight.data.zero_()\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                #    m.bias.data.zero_()\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "                #print(\"{}初始化OK!\".format(m))\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                assert m.kernel_size[0] == m.kernel_size[1]\n",
    "                initial_weight = get_upsampling_weight(\n",
    "                    m.in_channels, m.out_channels, m.kernel_size[0])\n",
    "                m.weight.data.copy_(initial_weight)\n",
    "                #print(\"{}初始化OK!\".format(m))        \n",
    "    \n",
    "    def make_stage_layers(self, cfg, batch_norm=False):\n",
    "        layers = []          \n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(self.in_channels, v, kernel_size=3, padding=self.padding)\n",
    "                if batch_norm:\n",
    "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "                else:\n",
    "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                self.in_channels = v\n",
    "                self.padding = 1 \n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def upscores(self, x, h, mode=8):\n",
    "        if mode == 8:            \n",
    "            h = self.upscore2(h)\n",
    "            upscore2 = h  # 1/16\n",
    "\n",
    "            h = self.score_pool4(self.pool4)\n",
    "            h = h[:, :, 5:5 + upscore2.size()[2], 5:5 + upscore2.size()[3]]\n",
    "            score_pool4c = h  # 1/16\n",
    "\n",
    "            h = upscore2 + score_pool4c  # 1/16\n",
    "            h = self.upscore_pool4(h)\n",
    "            upscore_pool4 = h  # 1/8\n",
    "\n",
    "            h = self.score_pool3(self.pool3)\n",
    "            h = h[:, :,\n",
    "                9:9 + upscore_pool4.size()[2],\n",
    "                9:9 + upscore_pool4.size()[3]]\n",
    "            score_pool3c = h  # 1/8\n",
    "\n",
    "            h = upscore_pool4 + score_pool3c  # 1/8\n",
    "\n",
    "            h = self.upscore8(h)\n",
    "            h = h[:, :, 31:31 + x.size()[2], 31:31 + x.size()[3]].contiguous()\n",
    "            return h\n",
    "        if mode == 16:\n",
    "            h = self.upscore2(h)\n",
    "            upscore2 = h  # 1/16\n",
    "\n",
    "            h = self.score_pool4(self.pool4)\n",
    "            h = h[:, :, 5:5 + upscore2.size()[2], 5:5 + upscore2.size()[3]]\n",
    "            score_pool4c = h  # 1/16\n",
    "\n",
    "            h = upscore2 + score_pool4c\n",
    "\n",
    "            h = self.upscore16(h)\n",
    "            h = h[:, :, 27:27 + x.size()[2], 27:27 + x.size()[3]]\n",
    "            return h\n",
    "        if mode == 32:\n",
    "            h = self.upscore(h)\n",
    "            h = h[:, :, 19:19 + x.size()[2], 19:19 + x.size()[3]]\n",
    "            return h\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = self.vgg_stage1(h)\n",
    "\n",
    "        h = self.vgg_stage2(h)\n",
    "\n",
    "        h = self.vgg_stage3(h)\n",
    "        self.pool3 = h\n",
    "\n",
    "        h = self.vgg_stage4(h)\n",
    "        self.pool4 = h\n",
    "\n",
    "        h = self.vgg_stage5(h)\n",
    "        self.pool5 = h\n",
    "\n",
    "        h = self.fc6(h)\n",
    "\n",
    "        h = self.fc7(h)\n",
    "        \n",
    "        h = self.score_fr(h)\n",
    "\n",
    "        h = self.upscores(x, h, mode=self.mode)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调用接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_dict(my_model_path, pretrained_path):\n",
    "    state_dict1 = torch.load(my_model_path) # 读取自己定义的模型，以获取参数名称\n",
    "    valid_name_list = list(state_dict1.keys())    \n",
    "    ext_name_list = ['upscore.weight', 'upscore16.weight']\n",
    "    valid_name_list.remove(ext_name_list[0])\n",
    "    valid_name_list.remove(ext_name_list[1])\n",
    "    state_dict2 = torch.load(pretrained_path)\n",
    "    i = 0\n",
    "    for k,v in state_dict2.items():\n",
    "        value = v.clone()\n",
    "        if state_dict1[valid_name_list[i]].shape == value.shape:\n",
    "            state_dict1[valid_name_list[i]] = value\n",
    "            i += 1\n",
    "    state_dict1[ext_name_list[0]] = torch.zeros([21, 21, 64, 64])\n",
    "    state_dict1[ext_name_list[1]] = torch.zeros([21, 21, 32, 32])\n",
    "    return state_dict1\n",
    "\n",
    "def get_myfcn(vgg_name, fcn_mode, pretrained_path):\n",
    "    \"\"\"\n",
    "    根据配置产生fcn网络结构\n",
    "    input:\n",
    "        vgg_name:  vgg_cfgs中的可选配置\n",
    "        fcn_mode:  fcn可选模式, 8; 16, 32\n",
    "        pretrained_path: True or False\n",
    "    output:\n",
    "        fcn_net:   fcn模型\n",
    "    \"\"\"\n",
    "    fcn_net = FCN(vgg_cfgs=vgg_name, mode=fcn_mode)\n",
    "    if pretrained_path:\n",
    "        print(\"开始加载预训练模型\")\n",
    "        #state_dict = torch.load(pretrained_path)\n",
    "        my_model_path = 'my_params.pth'\n",
    "        state_dict = get_state_dict(my_model_path, pretrained_path)\n",
    "        fcn_net.load_state_dict(state_dict)\n",
    "    return fcn_net\n",
    "\n",
    "def get_fcn8s(pretrained_path):\n",
    "    fcn_net = FCN8s()\n",
    "    state_dict = torch.load(pretrained_path)\n",
    "    fcn_net.load_state_dict(state_dict)\n",
    "    return fcn_net\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vgg_stage1.0.weight', 'vgg_stage1.0.bias', 'vgg_stage1.2.weight', 'vgg_stage1.2.bias', 'vgg_stage2.0.weight', 'vgg_stage2.0.bias', 'vgg_stage2.2.weight', 'vgg_stage2.2.bias', 'vgg_stage3.0.weight', 'vgg_stage3.0.bias', 'vgg_stage3.2.weight', 'vgg_stage3.2.bias', 'vgg_stage3.4.weight', 'vgg_stage3.4.bias', 'vgg_stage4.0.weight', 'vgg_stage4.0.bias', 'vgg_stage4.2.weight', 'vgg_stage4.2.bias', 'vgg_stage4.4.weight', 'vgg_stage4.4.bias', 'vgg_stage5.0.weight', 'vgg_stage5.0.bias', 'vgg_stage5.2.weight', 'vgg_stage5.2.bias', 'vgg_stage5.4.weight', 'vgg_stage5.4.bias', 'fc6.0.weight', 'fc6.0.bias', 'fc7.0.weight', 'fc7.0.bias', 'score_fr.weight', 'score_fr.bias', 'score_pool3.weight', 'score_pool3.bias', 'score_pool4.weight', 'score_pool4.bias', 'upscore.weight', 'upscore2.weight', 'upscore8.weight', 'upscore16.weight', 'upscore_pool4.weight']\n",
      "['conv1_1.weight', 'conv1_1.bias', 'conv1_2.weight', 'conv1_2.bias', 'conv2_1.weight', 'conv2_1.bias', 'conv2_2.weight', 'conv2_2.bias', 'conv3_1.weight', 'conv3_1.bias', 'conv3_2.weight', 'conv3_2.bias', 'conv3_3.weight', 'conv3_3.bias', 'conv4_1.weight', 'conv4_1.bias', 'conv4_2.weight', 'conv4_2.bias', 'conv4_3.weight', 'conv4_3.bias', 'conv5_1.weight', 'conv5_1.bias', 'conv5_2.weight', 'conv5_2.bias', 'conv5_3.weight', 'conv5_3.bias', 'fc6.weight', 'fc6.bias', 'fc7.weight', 'fc7.bias', 'score_fr.weight', 'score_fr.bias', 'score_pool3.weight', 'score_pool3.bias', 'score_pool4.weight', 'score_pool4.bias', 'upscore2.weight', 'upscore8.weight', 'upscore_pool4.weight']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "my_dict_name = list(myfcn_net.state_dict().keys())\n",
    "fcn8s_dict_name = list(fcn8s_net.state_dict().keys())\n",
    "print(my_dict_name)\n",
    "print(fcn8s_dict_name)\n",
    "#print(myfcn_net.state_dict()['upscore2.weight'])\n",
    "#print(fcn8s_net.state_dict()['upscore2.weight'])\n",
    "print(torch.equal(myfcn_net.state_dict()['upscore_pool4.weight'], fcn8s_net.state_dict()['upscore_pool4.weight']))\n",
    "# for i in range(len(fcn8s_dict_name)):\n",
    "#     my_tensor = myfcn_net.state_dict()[my_dict_name[i]]\n",
    "#     fcn8s_tensor = fcn8s_net.state_dict()[fcn8s_dict_name[i]]\n",
    "#     isEqual = torch.equal(my_tensor, fcn8s_tensor)\n",
    "#     print(\"{},{}\".format(my_dict_name[i], fcn8s_dict_name[i]))\n",
    "#     print(\"两种实现结果是否一致:{}\".format(isEqual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一个简单的模型初始化及模型参数恢复实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始加载预训练模型\n",
      "创建模型对象成功\n",
      "创建模型对象成功\n",
      "torch.Size([1, 3, 1213, 1546])\n",
      "tensor([[[[ 5.1597e+00,  5.3911e+00,  5.5899e+00,  ...,  8.0725e+00,\n",
      "            8.0070e+00,  7.9085e+00],\n",
      "          [ 5.3908e+00,  5.6326e+00,  5.8403e+00,  ...,  8.4336e+00,\n",
      "            8.3651e+00,  8.2622e+00],\n",
      "          [ 5.5884e+00,  5.8391e+00,  6.0543e+00,  ...,  8.7422e+00,\n",
      "            8.6714e+00,  8.5648e+00],\n",
      "          ...,\n",
      "          [ 8.7452e+00,  9.1371e+00,  9.4732e+00,  ...,  1.4179e+01,\n",
      "            1.4064e+01,  1.3891e+01],\n",
      "          [ 8.7551e+00,  9.1474e+00,  9.4837e+00,  ...,  1.4185e+01,\n",
      "            1.4070e+01,  1.3897e+01],\n",
      "          [ 8.7650e+00,  9.1577e+00,  9.4943e+00,  ...,  1.4192e+01,\n",
      "            1.4076e+01,  1.3903e+01]],\n",
      "\n",
      "         [[-5.8455e-01, -6.1039e-01, -6.3246e-01,  ..., -9.6674e-01,\n",
      "           -9.5810e-01, -9.4597e-01],\n",
      "          [-6.1081e-01, -6.3782e-01, -6.6088e-01,  ..., -1.0099e+00,\n",
      "           -1.0008e+00, -9.8811e-01],\n",
      "          [-6.3401e-01, -6.6205e-01, -6.8597e-01,  ..., -1.0474e+00,\n",
      "           -1.0379e+00, -1.0247e+00],\n",
      "          ...,\n",
      "          [-1.0393e+00, -1.0861e+00, -1.1268e+00,  ..., -1.7162e+00,\n",
      "           -1.7010e+00, -1.6796e+00],\n",
      "          [-1.0385e+00, -1.0852e+00, -1.1258e+00,  ..., -1.7167e+00,\n",
      "           -1.7016e+00, -1.6803e+00],\n",
      "          [-1.0376e+00, -1.0843e+00, -1.1248e+00,  ..., -1.7172e+00,\n",
      "           -1.7023e+00, -1.6810e+00]],\n",
      "\n",
      "         [[-7.9416e-01, -8.2999e-01, -8.6055e-01,  ..., -1.2447e+00,\n",
      "           -1.2341e+00, -1.2186e+00],\n",
      "          [-8.2966e-01, -8.6708e-01, -8.9898e-01,  ..., -1.3003e+00,\n",
      "           -1.2894e+00, -1.2732e+00],\n",
      "          [-8.6012e-01, -8.9891e-01, -9.3199e-01,  ..., -1.3477e+00,\n",
      "           -1.3363e+00, -1.3195e+00],\n",
      "          ...,\n",
      "          [-1.2277e+00, -1.2832e+00, -1.3308e+00,  ..., -2.0344e+00,\n",
      "           -2.0173e+00, -1.9919e+00],\n",
      "          [-1.2278e+00, -1.2832e+00, -1.3308e+00,  ..., -2.0369e+00,\n",
      "           -2.0199e+00, -1.9945e+00],\n",
      "          [-1.2278e+00, -1.2832e+00, -1.3307e+00,  ..., -2.0394e+00,\n",
      "           -2.0225e+00, -1.9972e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.4114e-01,  9.8368e-01,  1.0203e+00,  ...,  1.6306e+00,\n",
      "            1.6171e+00,  1.5970e+00],\n",
      "          [ 9.8244e-01,  1.0268e+00,  1.0651e+00,  ...,  1.7027e+00,\n",
      "            1.6886e+00,  1.6677e+00],\n",
      "          [ 1.0173e+00,  1.0633e+00,  1.1029e+00,  ...,  1.7634e+00,\n",
      "            1.7488e+00,  1.7271e+00],\n",
      "          ...,\n",
      "          [ 1.6262e+00,  1.6994e+00,  1.7635e+00,  ...,  2.8798e+00,\n",
      "            2.8548e+00,  2.8193e+00],\n",
      "          [ 1.6374e+00,  1.7109e+00,  1.7753e+00,  ...,  2.8938e+00,\n",
      "            2.8689e+00,  2.8332e+00],\n",
      "          [ 1.6485e+00,  1.7225e+00,  1.7870e+00,  ...,  2.9079e+00,\n",
      "            2.8830e+00,  2.8472e+00]],\n",
      "\n",
      "         [[-3.8839e-01, -4.0597e-01, -4.2083e-01,  ..., -6.2981e-01,\n",
      "           -6.2449e-01, -6.1626e-01],\n",
      "          [-4.0565e-01, -4.2401e-01, -4.3953e-01,  ..., -6.5744e-01,\n",
      "           -6.5188e-01, -6.4328e-01],\n",
      "          [-4.1990e-01, -4.3889e-01, -4.5495e-01,  ..., -6.8009e-01,\n",
      "           -6.7433e-01, -6.6544e-01],\n",
      "          ...,\n",
      "          [-6.2448e-01, -6.5305e-01, -6.7741e-01,  ..., -1.1534e+00,\n",
      "           -1.1465e+00, -1.1331e+00],\n",
      "          [-6.2646e-01, -6.5499e-01, -6.7938e-01,  ..., -1.1565e+00,\n",
      "           -1.1495e+00, -1.1363e+00],\n",
      "          [-6.2844e-01, -6.5694e-01, -6.8135e-01,  ..., -1.1596e+00,\n",
      "           -1.1525e+00, -1.1395e+00]],\n",
      "\n",
      "         [[-3.1419e-01, -3.2800e-01, -3.3931e-01,  ..., -4.0830e-01,\n",
      "           -4.0519e-01, -3.9981e-01],\n",
      "          [-3.2854e-01, -3.4298e-01, -3.5483e-01,  ..., -4.2656e-01,\n",
      "           -4.2327e-01, -4.1763e-01],\n",
      "          [-3.4071e-01, -3.5571e-01, -3.6806e-01,  ..., -4.4189e-01,\n",
      "           -4.3839e-01, -4.3251e-01],\n",
      "          ...,\n",
      "          [-3.3689e-01, -3.5182e-01, -3.6430e-01,  ..., -3.6530e-01,\n",
      "           -3.6410e-01, -3.6043e-01],\n",
      "          [-3.3717e-01, -3.5206e-01, -3.6451e-01,  ..., -3.6524e-01,\n",
      "           -3.6417e-01, -3.6064e-01],\n",
      "          [-3.3744e-01, -3.5230e-01, -3.6473e-01,  ..., -3.6518e-01,\n",
      "           -3.6423e-01, -3.6084e-01]]]], grad_fn=<CloneBackward>)\n"
     ]
    }
   ],
   "source": [
    "vgg_name = 'vgg_16'\n",
    "fcn_mode = 8\n",
    "pretrained_path = 'fcn8s_from_caffe.pth'   \n",
    "myfcn_net = get_myfcn(vgg_cfgs[vgg_name], fcn_mode, pretrained_path)\n",
    "#print(\"创建模型对象成功\")\n",
    "\n",
    "fcn8s_net = get_fcn8s(pretrained_path)\n",
    "#print(\"创建模型对象成功\")\n",
    "\n",
    "img = cv2.imread('dog.jpg')\n",
    "img = img/255\n",
    "img = np.transpose(img, (2,0,1))\n",
    "\n",
    "input = torch.from_numpy(img)\n",
    "input = input.unsqueeze(0)\n",
    "input = torch.tensor(input,dtype=torch.float32)\n",
    "\n",
    "print(input.shape)\n",
    "\n",
    "my_pred = myfcn_net(input)\n",
    "print(my_pred)\n",
    "#fcn8s_pred = fcn8s_net(input)\n",
    "#print(fcn8s_pred)\n",
    "#isEqual = torch.equal(my_pred, fcn8s_pred)\n",
    "#print(\"两种实现结果是否一致:{}\".format(isEqual))\n",
    "\n",
    "# # 保存模型\n",
    "# torch.save(fcn_net.state_dict(), 'my_params.pth')\n",
    "# print(\"模型保存完毕！！！\")\n",
    "# pretrained_path = 'my_params.pth'\n",
    "# fcn_test = get_fcn(vgg_cfgs[vgg_name], fcn_mode, pretrained_path)\n",
    "# print(\"模型加载完毕！！！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fcn8s_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
