{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 说明：\n",
    "### 1. 实现了2D的conv操作，并与pytorch的conv2d结果对比，完成了验证\n",
    "### 2. 基于实现的conv操作，对完整的多通道输入输出的场景进行了实现，并完成验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pycuda\n",
    "import pycuda.driver as drv\n",
    "import pycuda.autoinit\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from pycuda.elementwise import ElementwiseKernel\n",
    "from pycuda.scan import InclusiveScanKernel\n",
    "from pycuda.reduction import ReductionKernel\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "import pycuda.gpuarray as gpuarray\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pycuda版本:(2019, 1, 2)\n",
      "python版本:3.6.5 (default, Sep 29 2018, 16:40:34) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "print(\"pycuda版本:{}\".format(pycuda.VERSION))\n",
    "print(\"python版本:{}\".format(sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前环境可用gpu设备数量:4\n",
      "得到第2个gpu设备: drv.Device(i)\n",
      "当前gpu设备的计算能力:(6, 1)\n",
      "当前gpu设备的总内存:11178 MB\n",
      "\n",
      " gpu设备的所有属性名称及其值:\n",
      "ASYNC_ENGINE_COUNT : 2\n",
      "CAN_MAP_HOST_MEMORY : 1\n",
      "CLOCK_RATE : 1620000\n",
      "COMPUTE_CAPABILITY_MAJOR : 6\n",
      "COMPUTE_CAPABILITY_MINOR : 1\n",
      "COMPUTE_MODE : DEFAULT\n",
      "CONCURRENT_KERNELS : 1\n",
      "ECC_ENABLED : 0\n",
      "GLOBAL_L1_CACHE_SUPPORTED : 1\n",
      "GLOBAL_MEMORY_BUS_WIDTH : 352\n",
      "GPU_OVERLAP : 1\n",
      "INTEGRATED : 0\n",
      "KERNEL_EXEC_TIMEOUT : 0\n",
      "L2_CACHE_SIZE : 2883584\n",
      "LOCAL_L1_CACHE_SUPPORTED : 1\n",
      "MANAGED_MEMORY : 1\n",
      "MAXIMUM_SURFACE1D_LAYERED_LAYERS : 2048\n",
      "MAXIMUM_SURFACE1D_LAYERED_WIDTH : 32768\n",
      "MAXIMUM_SURFACE1D_WIDTH : 32768\n",
      "MAXIMUM_SURFACE2D_HEIGHT : 65536\n",
      "MAXIMUM_SURFACE2D_LAYERED_HEIGHT : 32768\n",
      "MAXIMUM_SURFACE2D_LAYERED_LAYERS : 2048\n",
      "MAXIMUM_SURFACE2D_LAYERED_WIDTH : 32768\n",
      "MAXIMUM_SURFACE2D_WIDTH : 131072\n",
      "MAXIMUM_SURFACE3D_DEPTH : 16384\n",
      "MAXIMUM_SURFACE3D_HEIGHT : 16384\n",
      "MAXIMUM_SURFACE3D_WIDTH : 16384\n",
      "MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS : 2046\n",
      "MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH : 32768\n",
      "MAXIMUM_SURFACECUBEMAP_WIDTH : 32768\n",
      "MAXIMUM_TEXTURE1D_LAYERED_LAYERS : 2048\n",
      "MAXIMUM_TEXTURE1D_LAYERED_WIDTH : 32768\n",
      "MAXIMUM_TEXTURE1D_LINEAR_WIDTH : 134217728\n",
      "MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH : 16384\n",
      "MAXIMUM_TEXTURE1D_WIDTH : 131072\n",
      "MAXIMUM_TEXTURE2D_ARRAY_HEIGHT : 32768\n",
      "MAXIMUM_TEXTURE2D_ARRAY_NUMSLICES : 2048\n",
      "MAXIMUM_TEXTURE2D_ARRAY_WIDTH : 32768\n",
      "MAXIMUM_TEXTURE2D_GATHER_HEIGHT : 32768\n",
      "MAXIMUM_TEXTURE2D_GATHER_WIDTH : 32768\n",
      "MAXIMUM_TEXTURE2D_HEIGHT : 65536\n",
      "MAXIMUM_TEXTURE2D_LINEAR_HEIGHT : 65000\n",
      "MAXIMUM_TEXTURE2D_LINEAR_PITCH : 2097120\n",
      "MAXIMUM_TEXTURE2D_LINEAR_WIDTH : 131072\n",
      "MAXIMUM_TEXTURE2D_MIPMAPPED_HEIGHT : 32768\n",
      "MAXIMUM_TEXTURE2D_MIPMAPPED_WIDTH : 32768\n",
      "MAXIMUM_TEXTURE2D_WIDTH : 131072\n",
      "MAXIMUM_TEXTURE3D_DEPTH : 16384\n",
      "MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE : 32768\n",
      "MAXIMUM_TEXTURE3D_HEIGHT : 16384\n",
      "MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE : 8192\n",
      "MAXIMUM_TEXTURE3D_WIDTH : 16384\n",
      "MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE : 8192\n",
      "MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS : 2046\n",
      "MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH : 32768\n",
      "MAXIMUM_TEXTURECUBEMAP_WIDTH : 32768\n",
      "MAX_BLOCK_DIM_X : 1024\n",
      "MAX_BLOCK_DIM_Y : 1024\n",
      "MAX_BLOCK_DIM_Z : 64\n",
      "MAX_GRID_DIM_X : 2147483647\n",
      "MAX_GRID_DIM_Y : 65535\n",
      "MAX_GRID_DIM_Z : 65535\n",
      "MAX_PITCH : 2147483647\n",
      "MAX_REGISTERS_PER_BLOCK : 65536\n",
      "MAX_REGISTERS_PER_MULTIPROCESSOR : 65536\n",
      "MAX_SHARED_MEMORY_PER_BLOCK : 49152\n",
      "MAX_SHARED_MEMORY_PER_MULTIPROCESSOR : 98304\n",
      "MAX_THREADS_PER_BLOCK : 1024\n",
      "MAX_THREADS_PER_MULTIPROCESSOR : 2048\n",
      "MEMORY_CLOCK_RATE : 5505000\n",
      "MULTIPROCESSOR_COUNT : 28\n",
      "MULTI_GPU_BOARD : 0\n",
      "MULTI_GPU_BOARD_GROUP_ID : 2\n",
      "PCI_BUS_ID : 3\n",
      "PCI_DEVICE_ID : 0\n",
      "PCI_DOMAIN_ID : 0\n",
      "STREAM_PRIORITIES_SUPPORTED : 1\n",
      "SURFACE_ALIGNMENT : 512\n",
      "TCC_DRIVER : 0\n",
      "TEXTURE_ALIGNMENT : 512\n",
      "TEXTURE_PITCH_ALIGNMENT : 32\n",
      "TOTAL_CONSTANT_MEMORY : 65536\n",
      "UNIFIED_ADDRESSING : 1\n",
      "WARP_SIZE : 32\n"
     ]
    }
   ],
   "source": [
    "drv.init() # 使用前需要初始化\n",
    "print(\"当前环境可用gpu设备数量:{}\".format(drv.Device.count()))\n",
    "i= 2\n",
    "gpu_device = drv.Device(i)\n",
    "print(\"得到第{}个gpu设备: drv.Device(i)\".format(i))\n",
    "print(\"当前gpu设备的计算能力:{}\".format(gpu_device.compute_capability()))\n",
    "print(\"当前gpu设备的总内存:{} MB\".format(gpu_device.total_memory()//(1024**2)))\n",
    "print(\"\\n gpu设备的所有属性名称及其值:\")\n",
    "attr_dict = gpu_device.get_attributes()\n",
    "for key,val in attr_dict.items():\n",
    "    print(\"{} : {}\".format(key, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于cuda的单通道conv2D模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = SourceModule('''   \n",
    "__global__ void conv_gpu(float *outputs, float *inputs, float *weights, int inputs_w, int inputs_h )\n",
    "{\n",
    "     const int kernel_size = 3;\n",
    "     const int   kernel_radius = 1; //(kernel_size-1)/2;  \n",
    "    __shared__ float shared_kernel[kernel_size*kernel_size];\n",
    "     int col = threadIdx.y + blockDim.y * blockIdx.y;\n",
    "     int row = threadIdx.x + blockDim.x * blockIdx.x;\n",
    "     int gLoc = row + inputs_w*col;\n",
    "     \n",
    "\n",
    "     for(int i=0 ;  i< kernel_size*kernel_size ; i+=1 )\n",
    "     shared_kernel[i]= weights[i];\n",
    "     \n",
    "    \n",
    "     float sum = 0; \n",
    "     float value = 0;\n",
    "     for(int i = -kernel_radius; i<=kernel_radius ; i++)\n",
    "        for(int j = -kernel_radius; j<=kernel_radius ;j++ ){  \n",
    "          if( (col+j)<0 ||(row+i) < 0 ||(row+i) > (inputs_w-1) ||(col+j )>(inputs_h-1) )\n",
    "          value = 0;\n",
    "          else        \n",
    "          value = inputs[gLoc + i + j * inputs_h];\n",
    "          sum += value * shared_kernel[(i+kernel_radius) + (j+kernel_radius)*kernel_size];\n",
    "    }\n",
    "       outputs[gLoc] = sum;\n",
    " }\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单通道验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.5344, -2.9753, -3.3508, -0.9424, -1.2960],\n",
      "          [-0.6342, -0.5778,  3.5405,  2.5334,  0.7346],\n",
      "          [ 0.9215, -0.7080, -3.9251, -6.9739, -1.2933],\n",
      "          [ 2.1979,  2.7678,  4.5203, -1.9241, -1.8704],\n",
      "          [-0.6884,  3.4865,  0.3182, -4.7315,  1.0770]]]])\n"
     ]
    }
   ],
   "source": [
    "inputs_torch = torch.randn(1,1,5,5)\n",
    "filters_torch = torch.randn(1,1,3,3)\n",
    "outputs_torch = F.conv2d(inputs_torch, filters_torch, padding=1)\n",
    "print(outputs_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.53436834 -2.9753168  -3.3508215  -0.9423924  -1.2960488 ]\n",
      " [-0.63421124 -0.57777417  3.5404694   2.5333502   0.7346365 ]\n",
      " [ 0.9214522  -0.708026   -3.9251387  -6.9739065  -1.2932689 ]\n",
      " [ 2.197879    2.7677586   4.5202622  -1.9240698  -1.8704407 ]\n",
      " [-0.68839467  3.4864678   0.31819493 -4.7314754   1.077028  ]]\n"
     ]
    }
   ],
   "source": [
    "conv_gpu = mod.get_function(\"conv_gpu\")\n",
    "\n",
    "inputs_np = inputs_torch.numpy()[0,0,:,:]\n",
    "filters_np = filters_torch.numpy()[0,0,:,:]\n",
    "(inputs_h,  inputs_w) = inputs_np.shape\n",
    "\n",
    "# 转换到cuda\n",
    "inputs_gpu = gpuarray.to_gpu(inputs_np)\n",
    "filters_gpu = gpuarray.to_gpu(filters_np)\n",
    "outputs_gpu = gpuarray.to_gpu(inputs_np.copy())\n",
    "\n",
    "conv_gpu(outputs_gpu, inputs_gpu , filters_gpu,  np.int32(inputs_w),  np.int32(inputs_h),  block=(5,1,1), grid=(1,5))\n",
    "# Pull the data back from the GPU.\n",
    "#cuda.memcpy_dtoh(destImage, destImage_gpu)\n",
    "outputs_np = outputs_gpu.get()\n",
    "print(outputs_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch卷积接口计算结果与自定义cuda卷积模块计算结果是否相等:True\n"
     ]
    }
   ],
   "source": [
    "isEqual = np.allclose(outputs_torch[0,0,:,:].numpy(), outputs_np)\n",
    "print(\"pytorch卷积接口计算结果与自定义cuda卷积模块计算结果是否相等:{}\".format(isEqual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整的多通道输入输出卷积实现及验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[  2.7610,  -0.0778,  -0.4686,   3.4005,  -3.2742],\n",
      "          [  5.6520,   0.9814,   9.5312,  11.2443,  -1.0960],\n",
      "          [  4.3053,   4.6576,   0.8058,  -4.2460,   4.2447],\n",
      "          [  3.2987,   7.4277,   1.0068,   3.6235,  11.8115],\n",
      "          [ -1.7737,   5.0722,  -0.7889,  -0.5678,  -1.6542]],\n",
      "\n",
      "         [[ -7.5778,   5.9519,   8.4655,   1.7258,   6.6949],\n",
      "          [ -1.7466,   6.9836,  -0.9286,   6.9171,  -2.8638],\n",
      "          [  5.8839,   4.2034, -16.9111,  -1.0687,  -0.1345],\n",
      "          [  4.3121,   5.9809,  -0.9009,  13.5289,   6.2836],\n",
      "          [  4.2167,   5.1541,  10.2324,  -7.6381,  -4.3288]],\n",
      "\n",
      "         [[ -1.7280,  11.8286,  -4.3150,  -9.1788,  -0.1405],\n",
      "          [  2.8384,   9.2456, -12.0575,  -1.7388,  13.9064],\n",
      "          [ -9.1081,   8.4183,   9.8954,   4.7973, -11.2288],\n",
      "          [ -0.3122,  -6.1656,   3.4151,  -6.0125,  -1.2578],\n",
      "          [ -4.2608,  -3.1783,   1.5610,   8.8211,  -1.1834]],\n",
      "\n",
      "         [[ -4.1348,   8.6961,  -1.0085,  -0.9764,  -3.1796],\n",
      "          [ -2.9400,  -7.6448,  -0.2325,   2.1828,  -1.9370],\n",
      "          [ -0.7396, -13.4760,  -2.8565,   5.4395,  -2.8278],\n",
      "          [  3.6163,  -5.2436,   6.9900,   5.2169,  13.6731],\n",
      "          [ -2.4448,   4.0467,  -0.6691,  -6.1708,  -1.0259]],\n",
      "\n",
      "         [[ -1.1169,   0.9911,   1.5573,  -3.3352,  -6.3845],\n",
      "          [  4.8062,   3.5736,   5.6329,   2.2106,  -2.4557],\n",
      "          [ -4.8631,   0.8958,  -4.0348, -16.4215,  -2.4569],\n",
      "          [ -1.2399,   4.8000,   1.9606,   7.9434,   5.8520],\n",
      "          [  1.0216,  -4.3565,   1.2827,  -1.0465,  -3.7123]],\n",
      "\n",
      "         [[ -2.3497,  14.1359,  -5.8823,  -1.6349,   4.9189],\n",
      "          [ -1.8196,   5.6131,  -9.4022,   2.1865,  10.5658],\n",
      "          [ -2.4323,   7.3174,  -7.2467, -16.0523,  -7.0354],\n",
      "          [ -3.9086,  -6.9694,  10.7877,   2.5458,  11.0035],\n",
      "          [ -0.3114,  -4.6553,   4.4969,  -2.0662,  -4.4013]],\n",
      "\n",
      "         [[ -1.6026,  -4.9049,   3.9459,   4.4602,   7.1044],\n",
      "          [ -2.8025,   5.1016,  11.9021,  12.6976,   7.2285],\n",
      "          [ 10.4049,  -1.2711,  -8.8476,  -2.8144,  -0.0421],\n",
      "          [  2.0033,   3.8576,   1.0408,  13.6396,  -2.2051],\n",
      "          [  4.1901,   4.5249,   0.8808, -10.8812,   2.4980]],\n",
      "\n",
      "         [[  4.7174,   4.4351,   0.2651,   2.7625,  -5.8662],\n",
      "          [  5.6275,  -5.7752,   0.9341,   4.5380,  -1.7578],\n",
      "          [ -4.0148,  -5.4495,  -5.2382,  -7.8099,   0.7920],\n",
      "          [ -8.7957,  -0.5150,   1.5131,  -1.1188,  10.8200],\n",
      "          [ -8.9676,  -1.2481,   0.4377,   1.3209,  -1.1483]]],\n",
      "\n",
      "\n",
      "        [[[ -1.5079,   7.4588,  -8.0390,   6.8588,   0.4840],\n",
      "          [ -1.6705,   0.7960,  -3.4409,   1.7325,   9.7019],\n",
      "          [  5.0421,  -1.4038,   4.4503, -12.4646,   5.0470],\n",
      "          [  8.0836,  -1.3689,   3.3491,  -3.6935,  -0.3305],\n",
      "          [ -1.1889,   7.3317,  -9.3291,   7.5424,  -0.5819]],\n",
      "\n",
      "         [[  8.1393,  -7.1949,   6.8988,  -5.6175,   4.3178],\n",
      "          [ -3.7378,  -1.3227,  -3.5986,   1.2126,   5.6082],\n",
      "          [  4.9364,  -0.8514,  -5.2939,   3.1634,   9.2068],\n",
      "          [ -2.2242,  11.1569,  -5.5274,   2.4822,   1.7681],\n",
      "          [  5.5970,  -8.2244,  -1.0291,   0.9465,   3.1525]],\n",
      "\n",
      "         [[ -3.0072,  -3.3006,  -0.0944,  -6.8504,   5.4626],\n",
      "          [  4.4751,  -0.8721,  -1.4218, -12.7812, -10.5194],\n",
      "          [ -5.6150,   9.9158,   1.9110,   0.6154,  -2.1655],\n",
      "          [  4.5511,  -3.0648,  -3.7274,   9.8647,   6.8747],\n",
      "          [  0.5412,  -8.1436,  -5.0287,  -1.4241,   2.2473]],\n",
      "\n",
      "         [[ -1.6341,   3.6392,   2.0644,   0.7430,  -7.1742],\n",
      "          [ -6.1946,  10.4102,  -1.6534,   6.8776,   0.1233],\n",
      "          [  0.5891,   2.3215, -10.1418,   7.6808,   4.2051],\n",
      "          [ 11.7010, -15.6446,   1.4765,  -7.3906,  -5.3218],\n",
      "          [ -4.8011,  -0.5069,   5.7360,   2.7095,  -3.7351]],\n",
      "\n",
      "         [[  4.8357,   4.8011,   3.8391,   1.9587,   1.4892],\n",
      "          [ -7.6924, -10.6222,  -4.8530,  -6.4485,   4.0541],\n",
      "          [ 10.0687, -10.1171,   5.0876,  -8.2202,  -6.5719],\n",
      "          [ -0.8966,  14.0817,   5.3966,   9.5710,   0.3129],\n",
      "          [ -3.1940,  -3.7799,  -9.4450,  -1.9468,  -0.7965]],\n",
      "\n",
      "         [[  0.1292,   3.9079,   3.4849,  -4.1987,  -4.3060],\n",
      "          [ -6.2713,  -2.9900,  -3.5004,  -3.1262,   2.1113],\n",
      "          [ -1.3826,  15.8805,  -0.5902,  -1.5765,   0.2881],\n",
      "          [  2.3381,  -0.5602,  -0.5641,   6.4997,   3.3091],\n",
      "          [  1.8102, -13.7979,  -3.1614,  -1.9868,  -0.7233]],\n",
      "\n",
      "         [[  1.8545,   4.0305,   0.6922,   0.1233,   2.3768],\n",
      "          [  5.1553,  -2.4416,  -5.9132,   0.0913,  13.9551],\n",
      "          [  6.7649,   5.4477,  -2.5735,  -8.4682,   6.6254],\n",
      "          [  0.7437,  -1.3158,   1.8217,   4.0495,  10.1132],\n",
      "          [ -7.2936,   1.4862,  -2.9231,   3.9399,   0.2267]],\n",
      "\n",
      "         [[  0.3035,   9.5036,  -5.8640,  -1.6584,  -5.8498],\n",
      "          [  1.9206,  14.0588,   4.1950,   1.9599,  -7.8273],\n",
      "          [  0.1458, -14.4174,   4.1644,  -0.5900,   3.1393],\n",
      "          [  0.1975,  -0.6213,  -5.3487,   1.4506,  -9.7474],\n",
      "          [ -1.6520,  -1.4076,   3.0471,  -1.3227,  -2.7282]]]])\n",
      "[[[[  2.7610364   -0.07781091  -0.4685911    3.400547    -3.2741988 ]\n",
      "   [  5.6520057    0.98136973   9.531198    11.24433     -1.0959711 ]\n",
      "   [  4.305338     4.657563     0.80576116  -4.245962     4.244685  ]\n",
      "   [  3.2986555    7.4276958    1.0068246    3.6234705   11.81151   ]\n",
      "   [ -1.7736968    5.0721707   -0.78893596  -0.56782496  -1.6542106 ]]\n",
      "\n",
      "  [[ -7.5777903    5.951947     8.465472     1.7258       6.694886  ]\n",
      "   [ -1.7465584    6.9835696   -0.92859757   6.917099    -2.8638434 ]\n",
      "   [  5.883924     4.203368   -16.911049    -1.0686737   -0.134485  ]\n",
      "   [  4.312081     5.980921    -0.9008821   13.528929     6.283636  ]\n",
      "   [  4.216653     5.1541433   10.232444    -7.6380687   -4.3288064 ]]\n",
      "\n",
      "  [[ -1.7280262   11.828556    -4.3150115   -9.178769    -0.14047602]\n",
      "   [  2.8383727    9.245616   -12.057466    -1.7387593   13.906437  ]\n",
      "   [ -9.108063     8.418291     9.895433     4.797262   -11.22877   ]\n",
      "   [ -0.31217325  -6.165624     3.4150968   -6.012484    -1.2577872 ]\n",
      "   [ -4.2608423   -3.1782725    1.5610464    8.82109     -1.1833552 ]]\n",
      "\n",
      "  [[ -4.1347694    8.6961      -1.008466    -0.976444    -3.1795993 ]\n",
      "   [ -2.9400082   -7.6447926   -0.2324549    2.1828136   -1.9369776 ]\n",
      "   [ -0.7396355  -13.476006    -2.8565392    5.439465    -2.8277626 ]\n",
      "   [  3.6162715   -5.243569     6.989985     5.216894    13.673114  ]\n",
      "   [ -2.444776     4.046726    -0.66905856  -6.1707773   -1.0258542 ]]\n",
      "\n",
      "  [[ -1.1168513    0.9910594    1.5572867   -3.335215    -6.3845077 ]\n",
      "   [  4.8061943    3.5736191    5.632945     2.2105944   -2.4556696 ]\n",
      "   [ -4.863125     0.8957808   -4.0348396  -16.421522    -2.4568846 ]\n",
      "   [ -1.2399409    4.7999706    1.9605851    7.9433813    5.851963  ]\n",
      "   [  1.0215662   -4.3565364    1.2826556   -1.0464637   -3.712273  ]]\n",
      "\n",
      "  [[ -2.3496783   14.135918    -5.8822813   -1.6348597    4.9188666 ]\n",
      "   [ -1.8195857    5.6130943   -9.402199     2.1865082   10.565812  ]\n",
      "   [ -2.4322965    7.3173923   -7.246671   -16.052345    -7.0353746 ]\n",
      "   [ -3.9086142   -6.969427    10.78771      2.5458283   11.003532  ]\n",
      "   [ -0.31143963  -4.6553283    4.4969263   -2.0661986   -4.401321  ]]\n",
      "\n",
      "  [[ -1.6025953   -4.904853     3.94586      4.4601836    7.104402  ]\n",
      "   [ -2.8024921    5.101569    11.902101    12.697558     7.2284656 ]\n",
      "   [ 10.404882    -1.271126    -8.847622    -2.814448    -0.04208088]\n",
      "   [  2.0033188    3.8575788    1.0407987   13.639605    -2.2051492 ]\n",
      "   [  4.190108     4.5249066    0.880798   -10.881163     2.497964  ]]\n",
      "\n",
      "  [[  4.7174344    4.435052     0.26514435   2.7624583   -5.866162  ]\n",
      "   [  5.6274867   -5.775153     0.93412066   4.538046    -1.7578334 ]\n",
      "   [ -4.014758    -5.4495196   -5.2382274   -7.8098974    0.7920382 ]\n",
      "   [ -8.79574     -0.514995     1.5130712   -1.1188257   10.820015  ]\n",
      "   [ -8.967563    -1.2481034    0.43769258   1.3209345   -1.1483048 ]]]\n",
      "\n",
      "\n",
      " [[[ -1.507909     7.458814    -8.038952     6.8588476    0.48404586]\n",
      "   [ -1.6705213    0.79597497  -3.4409351    1.7325318    9.701921  ]\n",
      "   [  5.042101    -1.4038323    4.450269   -12.464602     5.0469804 ]\n",
      "   [  8.083581    -1.3689437    3.3491497   -3.693464    -0.33053827]\n",
      "   [ -1.1888548    7.331749    -9.32905      7.5423827   -0.58187914]]\n",
      "\n",
      "  [[  8.139333    -7.1948776    6.898803    -5.6174808    4.317813  ]\n",
      "   [ -3.7378106   -1.3227315   -3.5986285    1.2126365    5.608211  ]\n",
      "   [  4.9364176   -0.85142565  -5.2939253    3.1633952    9.20682   ]\n",
      "   [ -2.2241755   11.156938    -5.5274405    2.4822156    1.7681212 ]\n",
      "   [  5.596977    -8.224409    -1.0290723    0.94649434   3.1524704 ]]\n",
      "\n",
      "  [[ -3.007167    -3.300616    -0.09437227  -6.85042      5.4626336 ]\n",
      "   [  4.4750986   -0.8720536   -1.4218062  -12.78123    -10.519388  ]\n",
      "   [ -5.615025     9.915761     1.9109783    0.6154101   -2.1654832 ]\n",
      "   [  4.5511165   -3.0647907   -3.7274132    9.864748     6.874693  ]\n",
      "   [  0.54124236  -8.143578    -5.0286655   -1.4241384    2.2472985 ]]\n",
      "\n",
      "  [[ -1.6340734    3.6391954    2.0644355    0.7430427   -7.1742325 ]\n",
      "   [ -6.1945877   10.4101925   -1.6533815    6.8776274    0.12332988]\n",
      "   [  0.589077     2.3214917  -10.141809     7.680798     4.205098  ]\n",
      "   [ 11.701033   -15.644589     1.4764967   -7.390602    -5.3218074 ]\n",
      "   [ -4.801149    -0.50685096   5.736041     2.7095146   -3.7350776 ]]\n",
      "\n",
      "  [[  4.8357453    4.801124     3.8390756    1.958736     1.4892066 ]\n",
      "   [ -7.6924257  -10.622184    -4.852978    -6.4485116    4.0540886 ]\n",
      "   [ 10.068734   -10.117073     5.0875664   -8.220187    -6.5718946 ]\n",
      "   [ -0.89662147  14.081704     5.3966417    9.57099      0.31290895]\n",
      "   [ -3.1939678   -3.7798893   -9.444959    -1.9467548   -0.79647636]]\n",
      "\n",
      "  [[  0.1291802    3.907897     3.4849346   -4.1986623   -4.3060217 ]\n",
      "   [ -6.271329    -2.9900243   -3.5004458   -3.126233     2.1112802 ]\n",
      "   [ -1.3826327   15.880537    -0.5901513   -1.5765178    0.28808492]\n",
      "   [  2.3380766   -0.5601537   -0.5640912    6.499673     3.3091488 ]\n",
      "   [  1.8102169  -13.797909    -3.1613617   -1.986751    -0.7233226 ]]\n",
      "\n",
      "  [[  1.8544528    4.0305347    0.69220614   0.12325954   2.376807  ]\n",
      "   [  5.1552806   -2.4415588   -5.9131575    0.09131102  13.955112  ]\n",
      "   [  6.764883     5.447698    -2.5735219   -8.468161     6.6253686 ]\n",
      "   [  0.7436819   -1.3157701    1.8217258    4.0495253   10.113221  ]\n",
      "   [ -7.29362      1.4862492   -2.923069     3.939917     0.22669268]]\n",
      "\n",
      "  [[  0.30348653   9.503609    -5.864045    -1.6584125   -5.8498316 ]\n",
      "   [  1.9205651   14.058824     4.194996     1.9599482   -7.827343  ]\n",
      "   [  0.14583385 -14.417402     4.1644225   -0.59002924   3.1393075 ]\n",
      "   [  0.1975429   -0.6213218   -5.3486795    1.4506028   -9.747419  ]\n",
      "   [ -1.651999    -1.4075509    3.0471225   -1.3227428   -2.72822   ]]]]\n"
     ]
    }
   ],
   "source": [
    "filters_torch = torch.randn(8,4,3,3)\n",
    "inputs_torch = torch.randn(2,4,5,5)\n",
    "outputs_torch = F.conv2d(inputs_torch, filters_torch, padding=1)\n",
    "(B, C_in, H, W) = inputs_torch.shape\n",
    "C_out = filters_torch.shape[0]\n",
    "outputs_np = np.full((B, C_out, H, W), 0, dtype=np.float32)\n",
    "\n",
    "for b in range(B):\n",
    "    for c_o in range(C_out):\n",
    "        for c_i in range(C_in):\n",
    "            inputs_np = inputs_torch.numpy()[b,c_i,:,:]\n",
    "            filters_np = filters_torch.numpy()[c_o,c_i,:,:]\n",
    "            (inputs_h,  inputs_w) = inputs_np.shape\n",
    "\n",
    "            # 转换到cuda\n",
    "            inputs_gpu = gpuarray.to_gpu(inputs_np)\n",
    "            filters_gpu = gpuarray.to_gpu(filters_np)\n",
    "            outputs_gpu = gpuarray.to_gpu(inputs_np.copy())\n",
    "\n",
    "            conv_gpu(outputs_gpu, inputs_gpu , filters_gpu,  np.int32(inputs_w),  np.int32(inputs_h),  block=(5,1,1), grid=(1,5))\n",
    "            # Pull the data back from the GPU.\n",
    "            #cuda.memcpy_dtoh(destImage, destImage_gpu)\n",
    "            outputs_tmp = outputs_gpu.get()\n",
    "            outputs_np[b, c_o, :, :] += outputs_tmp\n",
    "\n",
    "print(outputs_torch)\n",
    "print(outputs_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch输出的shape为:(2, 8, 5, 5)\n",
      "自定义cuda模块输出的shape为:torch.Size([2, 8, 5, 5])\n",
      "pytorch卷积接口计算结果与自定义cuda卷积模块计算结果是否相等:True\n"
     ]
    }
   ],
   "source": [
    "print('pytorch输出的shape为:{}'.format(outputs_np.shape))\n",
    "print('自定义cuda模块输出的shape为:{}'.format(outputs_torch.shape))\n",
    "isEqual = np.allclose(outputs_torch.numpy(), outputs_np)\n",
    "print(\"pytorch卷积接口计算结果与自定义cuda卷积模块计算结果是否相等:{}\".format(isEqual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析：\n",
    "### 目前只实现了2D结构的conv,对于实际场景中多通道输入和输出的高维场景，是通过for循环依次计算再合并来实现，并非最优结果， 最优结果目前尚在调试验证中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
