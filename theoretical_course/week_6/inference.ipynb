{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码说明\n",
    "## 1. 相关的接口在mnist_lenet_homework.py中\n",
    "## 2. 损失函数做了优化，采用交叉熵损失进行训练（代码中原始的损失计算方法几乎无法收敛）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_lenet_homework import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers=[]\n",
    "# add conv1 \n",
    "conv1= nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2)        # 6*28*28\n",
    "layers.append(conv1)\n",
    "pool2=nn.MaxPool2d(kernel_size=2, stride=2, padding=0)         # 6*14*14\n",
    "layers.append(pool2)\n",
    "# add conv3 \n",
    "conv3= nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)      # 16*10*10\n",
    "layers.append(conv3)\n",
    "pool4=nn.MaxPool2d(kernel_size=2, stride=2, padding=0)         # 16*5*5\n",
    "layers.append(pool4)\n",
    "# add conv5 \n",
    "conv5= nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1, padding=0)      # 120*1*1\n",
    "layers.append(conv5)\n",
    "f6 = nn.Linear(120, 84)\n",
    "layers.append(f6)\n",
    "output=nn.Linear(84,10)\n",
    "layers.append(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_all, image_label_all = load_mnist('../week_4/mnist', kind='train')\n",
    "num = 1000        # len(image_label_all)\n",
    "image_data=image_data_all[0:num]\n",
    "image_label=image_label_all[0:num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练之前模型准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始的未训练时模型的acc=0.072\n"
     ]
    }
   ],
   "source": [
    "print(\"初始的未训练时模型的acc=%s\"%(get_acc(image_data,image_label,layers,0,num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0,loss=tensor(2.0940, grad_fn=<NllLossBackward>)/10000000000000.0,train/test_acc:0.05/0.0\n",
      "epoch=1,loss=tensor(2.0919, grad_fn=<NllLossBackward>)/tensor(2.0940, grad_fn=<NllLossBackward>),train/test_acc:0.05/0.0\n",
      "epoch=2,loss=tensor(2.0898, grad_fn=<NllLossBackward>)/tensor(2.0919, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.0\n",
      "epoch=3,loss=tensor(2.0879, grad_fn=<NllLossBackward>)/tensor(2.0898, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.0\n",
      "epoch=4,loss=tensor(2.0860, grad_fn=<NllLossBackward>)/tensor(2.0879, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.0\n",
      "epoch=5,loss=tensor(2.0841, grad_fn=<NllLossBackward>)/tensor(2.0860, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.0\n",
      "epoch=6,loss=tensor(2.0823, grad_fn=<NllLossBackward>)/tensor(2.0841, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=7,loss=tensor(2.0805, grad_fn=<NllLossBackward>)/tensor(2.0823, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=8,loss=tensor(2.0787, grad_fn=<NllLossBackward>)/tensor(2.0805, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=9,loss=tensor(2.0769, grad_fn=<NllLossBackward>)/tensor(2.0787, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=10,loss=tensor(2.0751, grad_fn=<NllLossBackward>)/tensor(2.0769, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=11,loss=tensor(2.0733, grad_fn=<NllLossBackward>)/tensor(2.0751, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=12,loss=tensor(2.0715, grad_fn=<NllLossBackward>)/tensor(2.0733, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=13,loss=tensor(2.0697, grad_fn=<NllLossBackward>)/tensor(2.0715, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=14,loss=tensor(2.0679, grad_fn=<NllLossBackward>)/tensor(2.0697, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=15,loss=tensor(2.0661, grad_fn=<NllLossBackward>)/tensor(2.0679, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=16,loss=tensor(2.0642, grad_fn=<NllLossBackward>)/tensor(2.0661, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=17,loss=tensor(2.0624, grad_fn=<NllLossBackward>)/tensor(2.0642, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=18,loss=tensor(2.0606, grad_fn=<NllLossBackward>)/tensor(2.0624, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=19,loss=tensor(2.0588, grad_fn=<NllLossBackward>)/tensor(2.0606, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=20,loss=tensor(2.0570, grad_fn=<NllLossBackward>)/tensor(2.0588, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=21,loss=tensor(2.0551, grad_fn=<NllLossBackward>)/tensor(2.0570, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=22,loss=tensor(2.0533, grad_fn=<NllLossBackward>)/tensor(2.0551, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=23,loss=tensor(2.0515, grad_fn=<NllLossBackward>)/tensor(2.0533, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=24,loss=tensor(2.0497, grad_fn=<NllLossBackward>)/tensor(2.0515, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=25,loss=tensor(2.0479, grad_fn=<NllLossBackward>)/tensor(2.0497, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=26,loss=tensor(2.0461, grad_fn=<NllLossBackward>)/tensor(2.0479, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=27,loss=tensor(2.0443, grad_fn=<NllLossBackward>)/tensor(2.0461, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=28,loss=tensor(2.0425, grad_fn=<NllLossBackward>)/tensor(2.0443, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=29,loss=tensor(2.0407, grad_fn=<NllLossBackward>)/tensor(2.0425, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=30,loss=tensor(2.0389, grad_fn=<NllLossBackward>)/tensor(2.0407, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=31,loss=tensor(2.0371, grad_fn=<NllLossBackward>)/tensor(2.0389, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=32,loss=tensor(2.0353, grad_fn=<NllLossBackward>)/tensor(2.0371, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=33,loss=tensor(2.0336, grad_fn=<NllLossBackward>)/tensor(2.0353, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=34,loss=tensor(2.0318, grad_fn=<NllLossBackward>)/tensor(2.0336, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=35,loss=tensor(2.0300, grad_fn=<NllLossBackward>)/tensor(2.0318, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=36,loss=tensor(2.0283, grad_fn=<NllLossBackward>)/tensor(2.0300, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=37,loss=tensor(2.0266, grad_fn=<NllLossBackward>)/tensor(2.0283, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=38,loss=tensor(2.0248, grad_fn=<NllLossBackward>)/tensor(2.0266, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=39,loss=tensor(2.0231, grad_fn=<NllLossBackward>)/tensor(2.0248, grad_fn=<NllLossBackward>),train/test_acc:0.0625/0.05\n",
      "epoch=40,loss=tensor(2.0214, grad_fn=<NllLossBackward>)/tensor(2.0231, grad_fn=<NllLossBackward>),train/test_acc:0.075/0.05\n",
      "epoch=41,loss=tensor(2.0197, grad_fn=<NllLossBackward>)/tensor(2.0214, grad_fn=<NllLossBackward>),train/test_acc:0.075/0.05\n",
      "epoch=42,loss=tensor(2.0181, grad_fn=<NllLossBackward>)/tensor(2.0197, grad_fn=<NllLossBackward>),train/test_acc:0.075/0.05\n",
      "epoch=43,loss=tensor(2.0164, grad_fn=<NllLossBackward>)/tensor(2.0181, grad_fn=<NllLossBackward>),train/test_acc:0.075/0.05\n",
      "epoch=44,loss=tensor(2.0147, grad_fn=<NllLossBackward>)/tensor(2.0164, grad_fn=<NllLossBackward>),train/test_acc:0.075/0.05\n",
      "epoch=45,loss=tensor(2.0131, grad_fn=<NllLossBackward>)/tensor(2.0147, grad_fn=<NllLossBackward>),train/test_acc:0.075/0.05\n",
      "epoch=46,loss=tensor(2.0115, grad_fn=<NllLossBackward>)/tensor(2.0131, grad_fn=<NllLossBackward>),train/test_acc:0.075/0.05\n",
      "epoch=47,loss=tensor(2.0098, grad_fn=<NllLossBackward>)/tensor(2.0115, grad_fn=<NllLossBackward>),train/test_acc:0.075/0.05\n",
      "epoch=48,loss=tensor(2.0082, grad_fn=<NllLossBackward>)/tensor(2.0098, grad_fn=<NllLossBackward>),train/test_acc:0.075/0.05\n",
      "epoch=49,loss=tensor(2.0066, grad_fn=<NllLossBackward>)/tensor(2.0082, grad_fn=<NllLossBackward>),train/test_acc:0.075/0.05\n",
      "epoch=50,loss=tensor(2.0051, grad_fn=<NllLossBackward>)/tensor(2.0066, grad_fn=<NllLossBackward>),train/test_acc:0.075/0.05\n",
      "epoch=51,loss=tensor(2.0035, grad_fn=<NllLossBackward>)/tensor(2.0051, grad_fn=<NllLossBackward>),train/test_acc:0.075/0.05\n",
      "epoch=52,loss=tensor(2.0019, grad_fn=<NllLossBackward>)/tensor(2.0035, grad_fn=<NllLossBackward>),train/test_acc:0.075/0.05\n",
      "epoch=53,loss=tensor(2.0004, grad_fn=<NllLossBackward>)/tensor(2.0019, grad_fn=<NllLossBackward>),train/test_acc:0.075/0.05\n",
      "epoch=54,loss=tensor(1.9989, grad_fn=<NllLossBackward>)/tensor(2.0004, grad_fn=<NllLossBackward>),train/test_acc:0.075/0.05\n",
      "epoch=55,loss=tensor(1.9973, grad_fn=<NllLossBackward>)/tensor(1.9989, grad_fn=<NllLossBackward>),train/test_acc:0.075/0.05\n",
      "epoch=56,loss=tensor(1.9958, grad_fn=<NllLossBackward>)/tensor(1.9973, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.05\n",
      "epoch=57,loss=tensor(1.9943, grad_fn=<NllLossBackward>)/tensor(1.9958, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.05\n",
      "epoch=58,loss=tensor(1.9928, grad_fn=<NllLossBackward>)/tensor(1.9943, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.05\n",
      "epoch=59,loss=tensor(1.9913, grad_fn=<NllLossBackward>)/tensor(1.9928, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.05\n",
      "epoch=60,loss=tensor(1.9898, grad_fn=<NllLossBackward>)/tensor(1.9913, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.05\n",
      "epoch=61,loss=tensor(1.9883, grad_fn=<NllLossBackward>)/tensor(1.9898, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.05\n",
      "epoch=62,loss=tensor(1.9868, grad_fn=<NllLossBackward>)/tensor(1.9883, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.05\n",
      "epoch=63,loss=tensor(1.9853, grad_fn=<NllLossBackward>)/tensor(1.9868, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.05\n",
      "epoch=64,loss=tensor(1.9839, grad_fn=<NllLossBackward>)/tensor(1.9853, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.05\n",
      "epoch=65,loss=tensor(1.9824, grad_fn=<NllLossBackward>)/tensor(1.9839, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.05\n",
      "epoch=66,loss=tensor(1.9809, grad_fn=<NllLossBackward>)/tensor(1.9824, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=67,loss=tensor(1.9795, grad_fn=<NllLossBackward>)/tensor(1.9809, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=68,loss=tensor(1.9780, grad_fn=<NllLossBackward>)/tensor(1.9795, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=69,loss=tensor(1.9766, grad_fn=<NllLossBackward>)/tensor(1.9780, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=70,loss=tensor(1.9752, grad_fn=<NllLossBackward>)/tensor(1.9766, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=71,loss=tensor(1.9737, grad_fn=<NllLossBackward>)/tensor(1.9752, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=72,loss=tensor(1.9723, grad_fn=<NllLossBackward>)/tensor(1.9737, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=73,loss=tensor(1.9709, grad_fn=<NllLossBackward>)/tensor(1.9723, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=74,loss=tensor(1.9695, grad_fn=<NllLossBackward>)/tensor(1.9709, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=75,loss=tensor(1.9681, grad_fn=<NllLossBackward>)/tensor(1.9695, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=76,loss=tensor(1.9667, grad_fn=<NllLossBackward>)/tensor(1.9681, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=77,loss=tensor(1.9653, grad_fn=<NllLossBackward>)/tensor(1.9667, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=78,loss=tensor(1.9639, grad_fn=<NllLossBackward>)/tensor(1.9653, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=79,loss=tensor(1.9625, grad_fn=<NllLossBackward>)/tensor(1.9639, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=80,loss=tensor(1.9611, grad_fn=<NllLossBackward>)/tensor(1.9625, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=81,loss=tensor(1.9597, grad_fn=<NllLossBackward>)/tensor(1.9611, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=82,loss=tensor(1.9584, grad_fn=<NllLossBackward>)/tensor(1.9597, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=83,loss=tensor(1.9570, grad_fn=<NllLossBackward>)/tensor(1.9584, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=84,loss=tensor(1.9556, grad_fn=<NllLossBackward>)/tensor(1.9570, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=85,loss=tensor(1.9543, grad_fn=<NllLossBackward>)/tensor(1.9556, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=86,loss=tensor(1.9529, grad_fn=<NllLossBackward>)/tensor(1.9543, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=87,loss=tensor(1.9516, grad_fn=<NllLossBackward>)/tensor(1.9529, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=88,loss=tensor(1.9502, grad_fn=<NllLossBackward>)/tensor(1.9516, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=89,loss=tensor(1.9488, grad_fn=<NllLossBackward>)/tensor(1.9502, grad_fn=<NllLossBackward>),train/test_acc:0.0875/0.1\n",
      "epoch=90,loss=tensor(1.9475, grad_fn=<NllLossBackward>)/tensor(1.9488, grad_fn=<NllLossBackward>),train/test_acc:0.1/0.1\n",
      "epoch=91,loss=tensor(1.9461, grad_fn=<NllLossBackward>)/tensor(1.9475, grad_fn=<NllLossBackward>),train/test_acc:0.1/0.2\n",
      "epoch=92,loss=tensor(1.9448, grad_fn=<NllLossBackward>)/tensor(1.9461, grad_fn=<NllLossBackward>),train/test_acc:0.1/0.2\n",
      "epoch=93,loss=tensor(1.9434, grad_fn=<NllLossBackward>)/tensor(1.9448, grad_fn=<NllLossBackward>),train/test_acc:0.1/0.25\n",
      "epoch=94,loss=tensor(1.9421, grad_fn=<NllLossBackward>)/tensor(1.9434, grad_fn=<NllLossBackward>),train/test_acc:0.1/0.25\n",
      "epoch=95,loss=tensor(1.9408, grad_fn=<NllLossBackward>)/tensor(1.9421, grad_fn=<NllLossBackward>),train/test_acc:0.1/0.25\n",
      "epoch=96,loss=tensor(1.9394, grad_fn=<NllLossBackward>)/tensor(1.9408, grad_fn=<NllLossBackward>),train/test_acc:0.1/0.25\n",
      "epoch=97,loss=tensor(1.9381, grad_fn=<NllLossBackward>)/tensor(1.9394, grad_fn=<NllLossBackward>),train/test_acc:0.1/0.25\n",
      "epoch=98,loss=tensor(1.9367, grad_fn=<NllLossBackward>)/tensor(1.9381, grad_fn=<NllLossBackward>),train/test_acc:0.1125/0.25\n",
      "epoch=99,loss=tensor(1.9354, grad_fn=<NllLossBackward>)/tensor(1.9367, grad_fn=<NllLossBackward>),train/test_acc:0.1125/0.25\n",
      "epoch=100,loss=tensor(1.9340, grad_fn=<NllLossBackward>)/tensor(1.9354, grad_fn=<NllLossBackward>),train/test_acc:0.1125/0.25\n",
      "epoch=101,loss=tensor(1.9327, grad_fn=<NllLossBackward>)/tensor(1.9340, grad_fn=<NllLossBackward>),train/test_acc:0.1125/0.3\n",
      "epoch=102,loss=tensor(1.9313, grad_fn=<NllLossBackward>)/tensor(1.9327, grad_fn=<NllLossBackward>),train/test_acc:0.1125/0.3\n",
      "epoch=103,loss=tensor(1.9299, grad_fn=<NllLossBackward>)/tensor(1.9313, grad_fn=<NllLossBackward>),train/test_acc:0.125/0.3\n",
      "epoch=104,loss=tensor(1.9286, grad_fn=<NllLossBackward>)/tensor(1.9299, grad_fn=<NllLossBackward>),train/test_acc:0.125/0.3\n",
      "epoch=105,loss=tensor(1.9272, grad_fn=<NllLossBackward>)/tensor(1.9286, grad_fn=<NllLossBackward>),train/test_acc:0.125/0.3\n",
      "epoch=106,loss=tensor(1.9259, grad_fn=<NllLossBackward>)/tensor(1.9272, grad_fn=<NllLossBackward>),train/test_acc:0.125/0.3\n",
      "epoch=107,loss=tensor(1.9245, grad_fn=<NllLossBackward>)/tensor(1.9259, grad_fn=<NllLossBackward>),train/test_acc:0.125/0.35\n",
      "epoch=108,loss=tensor(1.9231, grad_fn=<NllLossBackward>)/tensor(1.9245, grad_fn=<NllLossBackward>),train/test_acc:0.125/0.35\n",
      "epoch=109,loss=tensor(1.9217, grad_fn=<NllLossBackward>)/tensor(1.9231, grad_fn=<NllLossBackward>),train/test_acc:0.125/0.35\n",
      "epoch=110,loss=tensor(1.9203, grad_fn=<NllLossBackward>)/tensor(1.9217, grad_fn=<NllLossBackward>),train/test_acc:0.1375/0.35\n",
      "epoch=111,loss=tensor(1.9189, grad_fn=<NllLossBackward>)/tensor(1.9203, grad_fn=<NllLossBackward>),train/test_acc:0.1375/0.35\n",
      "epoch=112,loss=tensor(1.9175, grad_fn=<NllLossBackward>)/tensor(1.9189, grad_fn=<NllLossBackward>),train/test_acc:0.1375/0.35\n",
      "epoch=113,loss=tensor(1.9160, grad_fn=<NllLossBackward>)/tensor(1.9175, grad_fn=<NllLossBackward>),train/test_acc:0.1375/0.35\n",
      "epoch=114,loss=tensor(1.9146, grad_fn=<NllLossBackward>)/tensor(1.9160, grad_fn=<NllLossBackward>),train/test_acc:0.1375/0.35\n",
      "epoch=115,loss=tensor(1.9131, grad_fn=<NllLossBackward>)/tensor(1.9146, grad_fn=<NllLossBackward>),train/test_acc:0.1375/0.35\n",
      "epoch=116,loss=tensor(1.9117, grad_fn=<NllLossBackward>)/tensor(1.9131, grad_fn=<NllLossBackward>),train/test_acc:0.1375/0.35\n",
      "epoch=117,loss=tensor(1.9102, grad_fn=<NllLossBackward>)/tensor(1.9117, grad_fn=<NllLossBackward>),train/test_acc:0.15/0.4\n",
      "epoch=118,loss=tensor(1.9087, grad_fn=<NllLossBackward>)/tensor(1.9102, grad_fn=<NllLossBackward>),train/test_acc:0.175/0.4\n",
      "epoch=119,loss=tensor(1.9071, grad_fn=<NllLossBackward>)/tensor(1.9087, grad_fn=<NllLossBackward>),train/test_acc:0.2/0.4\n",
      "epoch=120,loss=tensor(1.9056, grad_fn=<NllLossBackward>)/tensor(1.9071, grad_fn=<NllLossBackward>),train/test_acc:0.2/0.4\n",
      "epoch=121,loss=tensor(1.9039, grad_fn=<NllLossBackward>)/tensor(1.9056, grad_fn=<NllLossBackward>),train/test_acc:0.2/0.4\n",
      "epoch=122,loss=tensor(1.9023, grad_fn=<NllLossBackward>)/tensor(1.9039, grad_fn=<NllLossBackward>),train/test_acc:0.2/0.45\n",
      "epoch=123,loss=tensor(1.9006, grad_fn=<NllLossBackward>)/tensor(1.9023, grad_fn=<NllLossBackward>),train/test_acc:0.2/0.5\n",
      "epoch=124,loss=tensor(1.8989, grad_fn=<NllLossBackward>)/tensor(1.9006, grad_fn=<NllLossBackward>),train/test_acc:0.275/0.5\n",
      "epoch=125,loss=tensor(1.8971, grad_fn=<NllLossBackward>)/tensor(1.8989, grad_fn=<NllLossBackward>),train/test_acc:0.2875/0.5\n",
      "epoch=126,loss=tensor(1.8952, grad_fn=<NllLossBackward>)/tensor(1.8971, grad_fn=<NllLossBackward>),train/test_acc:0.3375/0.5\n",
      "epoch=127,loss=tensor(1.8933, grad_fn=<NllLossBackward>)/tensor(1.8952, grad_fn=<NllLossBackward>),train/test_acc:0.3625/0.5\n",
      "epoch=128,loss=tensor(1.8913, grad_fn=<NllLossBackward>)/tensor(1.8933, grad_fn=<NllLossBackward>),train/test_acc:0.375/0.5\n",
      "epoch=129,loss=tensor(1.8892, grad_fn=<NllLossBackward>)/tensor(1.8913, grad_fn=<NllLossBackward>),train/test_acc:0.4/0.5\n",
      "epoch=130,loss=tensor(1.8871, grad_fn=<NllLossBackward>)/tensor(1.8892, grad_fn=<NllLossBackward>),train/test_acc:0.425/0.5\n",
      "epoch=131,loss=tensor(1.8848, grad_fn=<NllLossBackward>)/tensor(1.8871, grad_fn=<NllLossBackward>),train/test_acc:0.475/0.55\n",
      "epoch=132,loss=tensor(1.8824, grad_fn=<NllLossBackward>)/tensor(1.8848, grad_fn=<NllLossBackward>),train/test_acc:0.4875/0.6\n",
      "epoch=133,loss=tensor(1.8798, grad_fn=<NllLossBackward>)/tensor(1.8824, grad_fn=<NllLossBackward>),train/test_acc:0.5/0.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=134,loss=tensor(1.8772, grad_fn=<NllLossBackward>)/tensor(1.8798, grad_fn=<NllLossBackward>),train/test_acc:0.5625/0.7\n",
      "epoch=135,loss=tensor(1.8745, grad_fn=<NllLossBackward>)/tensor(1.8772, grad_fn=<NllLossBackward>),train/test_acc:0.575/0.75\n",
      "epoch=136,loss=tensor(1.8718, grad_fn=<NllLossBackward>)/tensor(1.8745, grad_fn=<NllLossBackward>),train/test_acc:0.575/0.75\n",
      "epoch=137,loss=tensor(1.8690, grad_fn=<NllLossBackward>)/tensor(1.8718, grad_fn=<NllLossBackward>),train/test_acc:0.575/0.75\n",
      "epoch=138,loss=tensor(1.8663, grad_fn=<NllLossBackward>)/tensor(1.8690, grad_fn=<NllLossBackward>),train/test_acc:0.5875/0.75\n",
      "epoch=139,loss=tensor(1.8636, grad_fn=<NllLossBackward>)/tensor(1.8663, grad_fn=<NllLossBackward>),train/test_acc:0.6/0.75\n",
      "epoch=140,loss=tensor(1.8610, grad_fn=<NllLossBackward>)/tensor(1.8636, grad_fn=<NllLossBackward>),train/test_acc:0.6125/0.75\n",
      "epoch=141,loss=tensor(1.8584, grad_fn=<NllLossBackward>)/tensor(1.8610, grad_fn=<NllLossBackward>),train/test_acc:0.65/0.75\n",
      "epoch=142,loss=tensor(1.8560, grad_fn=<NllLossBackward>)/tensor(1.8584, grad_fn=<NllLossBackward>),train/test_acc:0.65/0.75\n",
      "epoch=143,loss=tensor(1.8536, grad_fn=<NllLossBackward>)/tensor(1.8560, grad_fn=<NllLossBackward>),train/test_acc:0.6625/0.75\n",
      "epoch=144,loss=tensor(1.8513, grad_fn=<NllLossBackward>)/tensor(1.8536, grad_fn=<NllLossBackward>),train/test_acc:0.6625/0.75\n",
      "epoch=145,loss=tensor(1.8490, grad_fn=<NllLossBackward>)/tensor(1.8513, grad_fn=<NllLossBackward>),train/test_acc:0.6625/0.75\n",
      "epoch=146,loss=tensor(1.8468, grad_fn=<NllLossBackward>)/tensor(1.8490, grad_fn=<NllLossBackward>),train/test_acc:0.675/0.75\n",
      "epoch=147,loss=tensor(1.8447, grad_fn=<NllLossBackward>)/tensor(1.8468, grad_fn=<NllLossBackward>),train/test_acc:0.7/0.75\n",
      "epoch=148,loss=tensor(1.8426, grad_fn=<NllLossBackward>)/tensor(1.8447, grad_fn=<NllLossBackward>),train/test_acc:0.7/0.75\n",
      "epoch=149,loss=tensor(1.8405, grad_fn=<NllLossBackward>)/tensor(1.8426, grad_fn=<NllLossBackward>),train/test_acc:0.725/0.75\n",
      "epoch=150,loss=tensor(1.8385, grad_fn=<NllLossBackward>)/tensor(1.8405, grad_fn=<NllLossBackward>),train/test_acc:0.725/0.75\n",
      "epoch=151,loss=tensor(1.8365, grad_fn=<NllLossBackward>)/tensor(1.8385, grad_fn=<NllLossBackward>),train/test_acc:0.725/0.75\n",
      "epoch=152,loss=tensor(1.8345, grad_fn=<NllLossBackward>)/tensor(1.8365, grad_fn=<NllLossBackward>),train/test_acc:0.725/0.75\n",
      "epoch=153,loss=tensor(1.8325, grad_fn=<NllLossBackward>)/tensor(1.8345, grad_fn=<NllLossBackward>),train/test_acc:0.725/0.75\n",
      "epoch=154,loss=tensor(1.8305, grad_fn=<NllLossBackward>)/tensor(1.8325, grad_fn=<NllLossBackward>),train/test_acc:0.7375/0.75\n",
      "epoch=155,loss=tensor(1.8286, grad_fn=<NllLossBackward>)/tensor(1.8305, grad_fn=<NllLossBackward>),train/test_acc:0.7375/0.75\n",
      "epoch=156,loss=tensor(1.8267, grad_fn=<NllLossBackward>)/tensor(1.8286, grad_fn=<NllLossBackward>),train/test_acc:0.75/0.75\n",
      "epoch=157,loss=tensor(1.8248, grad_fn=<NllLossBackward>)/tensor(1.8267, grad_fn=<NllLossBackward>),train/test_acc:0.75/0.75\n",
      "epoch=158,loss=tensor(1.8230, grad_fn=<NllLossBackward>)/tensor(1.8248, grad_fn=<NllLossBackward>),train/test_acc:0.75/0.8\n",
      "epoch=159,loss=tensor(1.8211, grad_fn=<NllLossBackward>)/tensor(1.8230, grad_fn=<NllLossBackward>),train/test_acc:0.75/0.8\n",
      "epoch=160,loss=tensor(1.8193, grad_fn=<NllLossBackward>)/tensor(1.8211, grad_fn=<NllLossBackward>),train/test_acc:0.75/0.8\n",
      "epoch=161,loss=tensor(1.8175, grad_fn=<NllLossBackward>)/tensor(1.8193, grad_fn=<NllLossBackward>),train/test_acc:0.75/0.85\n",
      "epoch=162,loss=tensor(1.8157, grad_fn=<NllLossBackward>)/tensor(1.8175, grad_fn=<NllLossBackward>),train/test_acc:0.7625/0.85\n",
      "epoch=163,loss=tensor(1.8139, grad_fn=<NllLossBackward>)/tensor(1.8157, grad_fn=<NllLossBackward>),train/test_acc:0.7625/0.85\n",
      "epoch=164,loss=tensor(1.8121, grad_fn=<NllLossBackward>)/tensor(1.8139, grad_fn=<NllLossBackward>),train/test_acc:0.7625/0.85\n",
      "epoch=165,loss=tensor(1.8104, grad_fn=<NllLossBackward>)/tensor(1.8121, grad_fn=<NllLossBackward>),train/test_acc:0.7625/0.85\n",
      "epoch=166,loss=tensor(1.8087, grad_fn=<NllLossBackward>)/tensor(1.8104, grad_fn=<NllLossBackward>),train/test_acc:0.7625/0.85\n",
      "epoch=167,loss=tensor(1.8070, grad_fn=<NllLossBackward>)/tensor(1.8087, grad_fn=<NllLossBackward>),train/test_acc:0.775/0.85\n",
      "epoch=168,loss=tensor(1.8053, grad_fn=<NllLossBackward>)/tensor(1.8070, grad_fn=<NllLossBackward>),train/test_acc:0.775/0.85\n",
      "epoch=169,loss=tensor(1.8037, grad_fn=<NllLossBackward>)/tensor(1.8053, grad_fn=<NllLossBackward>),train/test_acc:0.775/0.85\n",
      "epoch=170,loss=tensor(1.8020, grad_fn=<NllLossBackward>)/tensor(1.8037, grad_fn=<NllLossBackward>),train/test_acc:0.775/0.85\n",
      "epoch=171,loss=tensor(1.8004, grad_fn=<NllLossBackward>)/tensor(1.8020, grad_fn=<NllLossBackward>),train/test_acc:0.775/0.8\n",
      "epoch=172,loss=tensor(1.7988, grad_fn=<NllLossBackward>)/tensor(1.8004, grad_fn=<NllLossBackward>),train/test_acc:0.775/0.8\n",
      "epoch=173,loss=tensor(1.7972, grad_fn=<NllLossBackward>)/tensor(1.7988, grad_fn=<NllLossBackward>),train/test_acc:0.775/0.8\n",
      "epoch=174,loss=tensor(1.7956, grad_fn=<NllLossBackward>)/tensor(1.7972, grad_fn=<NllLossBackward>),train/test_acc:0.775/0.8\n",
      "epoch=175,loss=tensor(1.7941, grad_fn=<NllLossBackward>)/tensor(1.7956, grad_fn=<NllLossBackward>),train/test_acc:0.775/0.8\n",
      "epoch=176,loss=tensor(1.7925, grad_fn=<NllLossBackward>)/tensor(1.7941, grad_fn=<NllLossBackward>),train/test_acc:0.775/0.8\n",
      "epoch=177,loss=tensor(1.7910, grad_fn=<NllLossBackward>)/tensor(1.7925, grad_fn=<NllLossBackward>),train/test_acc:0.775/0.8\n",
      "epoch=178,loss=tensor(1.7895, grad_fn=<NllLossBackward>)/tensor(1.7910, grad_fn=<NllLossBackward>),train/test_acc:0.775/0.8\n",
      "epoch=179,loss=tensor(1.7880, grad_fn=<NllLossBackward>)/tensor(1.7895, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=180,loss=tensor(1.7865, grad_fn=<NllLossBackward>)/tensor(1.7880, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=181,loss=tensor(1.7851, grad_fn=<NllLossBackward>)/tensor(1.7865, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=182,loss=tensor(1.7836, grad_fn=<NllLossBackward>)/tensor(1.7851, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=183,loss=tensor(1.7822, grad_fn=<NllLossBackward>)/tensor(1.7836, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=184,loss=tensor(1.7808, grad_fn=<NllLossBackward>)/tensor(1.7822, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=185,loss=tensor(1.7794, grad_fn=<NllLossBackward>)/tensor(1.7808, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=186,loss=tensor(1.7780, grad_fn=<NllLossBackward>)/tensor(1.7794, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=187,loss=tensor(1.7767, grad_fn=<NllLossBackward>)/tensor(1.7780, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=188,loss=tensor(1.7753, grad_fn=<NllLossBackward>)/tensor(1.7767, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=189,loss=tensor(1.7740, grad_fn=<NllLossBackward>)/tensor(1.7753, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=190,loss=tensor(1.7727, grad_fn=<NllLossBackward>)/tensor(1.7740, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=191,loss=tensor(1.7714, grad_fn=<NllLossBackward>)/tensor(1.7727, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=192,loss=tensor(1.7701, grad_fn=<NllLossBackward>)/tensor(1.7714, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=193,loss=tensor(1.7689, grad_fn=<NllLossBackward>)/tensor(1.7701, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=194,loss=tensor(1.7676, grad_fn=<NllLossBackward>)/tensor(1.7689, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=195,loss=tensor(1.7664, grad_fn=<NllLossBackward>)/tensor(1.7676, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=196,loss=tensor(1.7652, grad_fn=<NllLossBackward>)/tensor(1.7664, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=197,loss=tensor(1.7640, grad_fn=<NllLossBackward>)/tensor(1.7652, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=198,loss=tensor(1.7628, grad_fn=<NllLossBackward>)/tensor(1.7640, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=199,loss=tensor(1.7616, grad_fn=<NllLossBackward>)/tensor(1.7628, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=200,loss=tensor(1.7605, grad_fn=<NllLossBackward>)/tensor(1.7616, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=201,loss=tensor(1.7593, grad_fn=<NllLossBackward>)/tensor(1.7605, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=202,loss=tensor(1.7582, grad_fn=<NllLossBackward>)/tensor(1.7593, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=203,loss=tensor(1.7571, grad_fn=<NllLossBackward>)/tensor(1.7582, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=204,loss=tensor(1.7560, grad_fn=<NllLossBackward>)/tensor(1.7571, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=205,loss=tensor(1.7549, grad_fn=<NllLossBackward>)/tensor(1.7560, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=206,loss=tensor(1.7538, grad_fn=<NllLossBackward>)/tensor(1.7549, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=207,loss=tensor(1.7527, grad_fn=<NllLossBackward>)/tensor(1.7538, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=208,loss=tensor(1.7517, grad_fn=<NllLossBackward>)/tensor(1.7527, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=209,loss=tensor(1.7506, grad_fn=<NllLossBackward>)/tensor(1.7517, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=210,loss=tensor(1.7496, grad_fn=<NllLossBackward>)/tensor(1.7506, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=211,loss=tensor(1.7485, grad_fn=<NllLossBackward>)/tensor(1.7496, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=212,loss=tensor(1.7475, grad_fn=<NllLossBackward>)/tensor(1.7485, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=213,loss=tensor(1.7465, grad_fn=<NllLossBackward>)/tensor(1.7475, grad_fn=<NllLossBackward>),train/test_acc:0.7875/0.8\n",
      "epoch=214,loss=tensor(1.7455, grad_fn=<NllLossBackward>)/tensor(1.7465, grad_fn=<NllLossBackward>),train/test_acc:0.8/0.8\n",
      "epoch=215,loss=tensor(1.7445, grad_fn=<NllLossBackward>)/tensor(1.7455, grad_fn=<NllLossBackward>),train/test_acc:0.8/0.85\n",
      "epoch=216,loss=tensor(1.7435, grad_fn=<NllLossBackward>)/tensor(1.7445, grad_fn=<NllLossBackward>),train/test_acc:0.8/0.85\n",
      "epoch=217,loss=tensor(1.7426, grad_fn=<NllLossBackward>)/tensor(1.7435, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=218,loss=tensor(1.7416, grad_fn=<NllLossBackward>)/tensor(1.7426, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=219,loss=tensor(1.7407, grad_fn=<NllLossBackward>)/tensor(1.7416, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=220,loss=tensor(1.7397, grad_fn=<NllLossBackward>)/tensor(1.7407, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=221,loss=tensor(1.7388, grad_fn=<NllLossBackward>)/tensor(1.7397, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=222,loss=tensor(1.7379, grad_fn=<NllLossBackward>)/tensor(1.7388, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=223,loss=tensor(1.7370, grad_fn=<NllLossBackward>)/tensor(1.7379, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=224,loss=tensor(1.7361, grad_fn=<NllLossBackward>)/tensor(1.7370, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=225,loss=tensor(1.7352, grad_fn=<NllLossBackward>)/tensor(1.7361, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=226,loss=tensor(1.7343, grad_fn=<NllLossBackward>)/tensor(1.7352, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=227,loss=tensor(1.7334, grad_fn=<NllLossBackward>)/tensor(1.7343, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=228,loss=tensor(1.7325, grad_fn=<NllLossBackward>)/tensor(1.7334, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=229,loss=tensor(1.7317, grad_fn=<NllLossBackward>)/tensor(1.7325, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=230,loss=tensor(1.7308, grad_fn=<NllLossBackward>)/tensor(1.7317, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=231,loss=tensor(1.7299, grad_fn=<NllLossBackward>)/tensor(1.7308, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=232,loss=tensor(1.7291, grad_fn=<NllLossBackward>)/tensor(1.7299, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=233,loss=tensor(1.7283, grad_fn=<NllLossBackward>)/tensor(1.7291, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=234,loss=tensor(1.7274, grad_fn=<NllLossBackward>)/tensor(1.7283, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=235,loss=tensor(1.7266, grad_fn=<NllLossBackward>)/tensor(1.7274, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=236,loss=tensor(1.7258, grad_fn=<NllLossBackward>)/tensor(1.7266, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=237,loss=tensor(1.7250, grad_fn=<NllLossBackward>)/tensor(1.7258, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=238,loss=tensor(1.7242, grad_fn=<NllLossBackward>)/tensor(1.7250, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=239,loss=tensor(1.7234, grad_fn=<NllLossBackward>)/tensor(1.7242, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=240,loss=tensor(1.7226, grad_fn=<NllLossBackward>)/tensor(1.7234, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=241,loss=tensor(1.7218, grad_fn=<NllLossBackward>)/tensor(1.7226, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=242,loss=tensor(1.7210, grad_fn=<NllLossBackward>)/tensor(1.7218, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=243,loss=tensor(1.7203, grad_fn=<NllLossBackward>)/tensor(1.7210, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=244,loss=tensor(1.7195, grad_fn=<NllLossBackward>)/tensor(1.7203, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=245,loss=tensor(1.7188, grad_fn=<NllLossBackward>)/tensor(1.7195, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=246,loss=tensor(1.7180, grad_fn=<NllLossBackward>)/tensor(1.7188, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=247,loss=tensor(1.7173, grad_fn=<NllLossBackward>)/tensor(1.7180, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=248,loss=tensor(1.7165, grad_fn=<NllLossBackward>)/tensor(1.7173, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=249,loss=tensor(1.7158, grad_fn=<NllLossBackward>)/tensor(1.7165, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=250,loss=tensor(1.7151, grad_fn=<NllLossBackward>)/tensor(1.7158, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=251,loss=tensor(1.7144, grad_fn=<NllLossBackward>)/tensor(1.7151, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=252,loss=tensor(1.7136, grad_fn=<NllLossBackward>)/tensor(1.7144, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=253,loss=tensor(1.7129, grad_fn=<NllLossBackward>)/tensor(1.7136, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=254,loss=tensor(1.7122, grad_fn=<NllLossBackward>)/tensor(1.7129, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=255,loss=tensor(1.7115, grad_fn=<NllLossBackward>)/tensor(1.7122, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=256,loss=tensor(1.7109, grad_fn=<NllLossBackward>)/tensor(1.7115, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=257,loss=tensor(1.7102, grad_fn=<NllLossBackward>)/tensor(1.7109, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=258,loss=tensor(1.7095, grad_fn=<NllLossBackward>)/tensor(1.7102, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=259,loss=tensor(1.7088, grad_fn=<NllLossBackward>)/tensor(1.7095, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=260,loss=tensor(1.7082, grad_fn=<NllLossBackward>)/tensor(1.7088, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=261,loss=tensor(1.7075, grad_fn=<NllLossBackward>)/tensor(1.7082, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=262,loss=tensor(1.7068, grad_fn=<NllLossBackward>)/tensor(1.7075, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=263,loss=tensor(1.7062, grad_fn=<NllLossBackward>)/tensor(1.7068, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=264,loss=tensor(1.7055, grad_fn=<NllLossBackward>)/tensor(1.7062, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=265,loss=tensor(1.7049, grad_fn=<NllLossBackward>)/tensor(1.7055, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=266,loss=tensor(1.7042, grad_fn=<NllLossBackward>)/tensor(1.7049, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=267,loss=tensor(1.7036, grad_fn=<NllLossBackward>)/tensor(1.7042, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=268,loss=tensor(1.7030, grad_fn=<NllLossBackward>)/tensor(1.7036, grad_fn=<NllLossBackward>),train/test_acc:0.8125/0.85\n",
      "epoch=269,loss=tensor(1.7023, grad_fn=<NllLossBackward>)/tensor(1.7030, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.85\n",
      "epoch=270,loss=tensor(1.7017, grad_fn=<NllLossBackward>)/tensor(1.7023, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=271,loss=tensor(1.7011, grad_fn=<NllLossBackward>)/tensor(1.7017, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=272,loss=tensor(1.7005, grad_fn=<NllLossBackward>)/tensor(1.7011, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=273,loss=tensor(1.6999, grad_fn=<NllLossBackward>)/tensor(1.7005, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=274,loss=tensor(1.6993, grad_fn=<NllLossBackward>)/tensor(1.6999, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=275,loss=tensor(1.6987, grad_fn=<NllLossBackward>)/tensor(1.6993, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=276,loss=tensor(1.6981, grad_fn=<NllLossBackward>)/tensor(1.6987, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=277,loss=tensor(1.6975, grad_fn=<NllLossBackward>)/tensor(1.6981, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=278,loss=tensor(1.6969, grad_fn=<NllLossBackward>)/tensor(1.6975, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=279,loss=tensor(1.6963, grad_fn=<NllLossBackward>)/tensor(1.6969, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=280,loss=tensor(1.6957, grad_fn=<NllLossBackward>)/tensor(1.6963, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=281,loss=tensor(1.6951, grad_fn=<NllLossBackward>)/tensor(1.6957, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=282,loss=tensor(1.6946, grad_fn=<NllLossBackward>)/tensor(1.6951, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=283,loss=tensor(1.6940, grad_fn=<NllLossBackward>)/tensor(1.6946, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=284,loss=tensor(1.6934, grad_fn=<NllLossBackward>)/tensor(1.6940, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=285,loss=tensor(1.6929, grad_fn=<NllLossBackward>)/tensor(1.6934, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=286,loss=tensor(1.6923, grad_fn=<NllLossBackward>)/tensor(1.6929, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=287,loss=tensor(1.6918, grad_fn=<NllLossBackward>)/tensor(1.6923, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=288,loss=tensor(1.6912, grad_fn=<NllLossBackward>)/tensor(1.6918, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=289,loss=tensor(1.6906, grad_fn=<NllLossBackward>)/tensor(1.6912, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=290,loss=tensor(1.6901, grad_fn=<NllLossBackward>)/tensor(1.6906, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=291,loss=tensor(1.6896, grad_fn=<NllLossBackward>)/tensor(1.6901, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=292,loss=tensor(1.6890, grad_fn=<NllLossBackward>)/tensor(1.6896, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=293,loss=tensor(1.6885, grad_fn=<NllLossBackward>)/tensor(1.6890, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=294,loss=tensor(1.6879, grad_fn=<NllLossBackward>)/tensor(1.6885, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=295,loss=tensor(1.6874, grad_fn=<NllLossBackward>)/tensor(1.6879, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=296,loss=tensor(1.6869, grad_fn=<NllLossBackward>)/tensor(1.6874, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=297,loss=tensor(1.6864, grad_fn=<NllLossBackward>)/tensor(1.6869, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=298,loss=tensor(1.6858, grad_fn=<NllLossBackward>)/tensor(1.6864, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n",
      "epoch=299,loss=tensor(1.6853, grad_fn=<NllLossBackward>)/tensor(1.6858, grad_fn=<NllLossBackward>),train/test_acc:0.825/0.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1)),\n",
       " Linear(in_features=120, out_features=84, bias=True),\n",
       " Linear(in_features=84, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "train_model(image_data,image_label,layers,lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练之后准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练完成后模型的acc=0.823\n"
     ]
    }
   ],
   "source": [
    "print(\"训练完成后模型的acc=%s\"%(get_acc(image_data,image_label,layers,0,num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
